The Parsing Challenge Explained

        txxt is a plain text format that is very powerful and very easy to read and write.
        That is made possible by using "invisible syntax" that is, leveraging human's 

        - Spatial skills by encoding structure with indentation
        - Long history of shared conventions that are engrrained and carry low cognitive load.

        There is no free lunch, however, and all that good vibes come at the cost of pushing the complexity to the parser. This is why txxt, as being a dead simple format, with 4 syntax elements is actually pretty tricky to parse. txxx is indentation significant, recursive , look ahead intensive and some parts are statefull.

        While any of these are not particularly hard, the combination is not simple. For starters it precluded the project from using a library since there isn't one that can do all of these, that is, we build a custom parser, by hand. We will walk through the fundamentals, the reality and the things we want to fix.

1. From first Principles

        1.1 First things first: Verbatim must be marked.
         
        	txxt has verbatim blocks:  these contain content encoded in (likely) other formats. 
        	The text-book example for this is code sample in various programing languages.

        	This has a clear implication: the very first thing you need to do is mark verbatim blocks content, because you can't parse them as txxt.
        	It's not just that is would be wasteful, but wrong. For example txxt cares about indentation and blank lines, and the content in verbatim blocks 
        	can be parsed as those. 

        	So the first pass is to mark the soure string's verbatim blocks . We should say this block starts at line x and end in line y, for each block.

        	This is also because, as verbatim blocks are stateful (once inside one, you ignore anything but the end marker for the block), parsing it separately has the benefit of removing all stateful parsing. Yay. 

        1.2. Understanding other elements  

        	We need to custom write the parser leveraging everything that allows us to reduce complexities and isolating the hardest parts. 
        	Let's take a look at what parsing related characterirstics sets the various elements a part.


        	1. Inlines

        		Inlines will happen in a raw text, in a pargragraph or list or section title.
        		Parsing them is very straightforoward as they are not dependend on indentation, context or look ahead and have explicit start and end markers.
        		Hence inline parsing can be isolated into a function that 
        			- Though a custom simple state machine matches any start marker, set the state to be inside an inlie and pop the state when out.
        			- Creates (if such elements are present) a contaner with processed text elements ("plain text" is treated as an inline element which allows is to be processed and treated like all).
        		
        		For this reason, inlines can be processed last thing, and given that they don't change document structure, they are very simple.

        	2. Annotations 
        		Annotations are still simple, although they have a few forms (single and multiline). The multinie is trickier because it does not require to be followed by a blank line (because annotations work much better next to the item they are annotating)

        		Annotations have another peculiarity:  they are not part of the document content tree, instead they are attached to the element their are annotating.
        		The rule is simple: they attach to the next element after them.  If there is none, to their parent element (the doc root if it starts with annotatons)

        	3. Paragraphs

        		By themselves: as simple as can be. One or more lines of code, surrounded by blank lines.
        		One special casing, in order to be able to have dialogs, which could be confused with lists, if the first line of the dialog ends with a double end-pontuaction where the very last has to be a period, the liens are paragraph not a list (.., !., ?., ...., ???1!)

        	4. Verbatim Blocks

        		As mentioned before these blocks need to be marked up front so we don't parse ttheir content.
        		It's fine (and required) that we parse their start and end lines. These should be space normalized, level nested accounted for, parse their parameters. It's just that their inner content, that we don't touch.

        		Becuase we have to know which lines not to parse first, this has to be the very first thing the parser does. 
        		Note that this is not about parsing the block, just identifing start, stop and contend (the gap between these).

        		Since this scan has to happen first, these blocks need to be very easy to identify, hence they are very clearly marked.

        	5. Lists

        		Lists are tricker to parse, although, not on their own, but, like paragraphs on their interactions with titles.
        		Lists can be unordered (-) and ordered (1., a)
        		Lists can be nested.
        		Odering gets marked by first line,  can be mixed, only first item per level sets the numbering style.
        		Cannot be single level and single item (not a list, a phrase), which makes disambiguation with paragraphs easier.
        		Inner lists are +1  indented.

        	6. Sections And Section Titles

        		Sections are denoted by 

        			- +1 indend
        			- Have to have at least one item
        			- Preceded by the section title

        		the best copmendium we've got for the edge cases are txxt-documents/nesting-edge-cases.txxt



2. Parsing, a tour

    The 5 Parser Passes

    2.1. Pass 1: Line Parsing (line_parser.py)

        - Function: parse_to_lines() at line 70
        - Input: Raw text string
        - Output: Document[Line] nodes
        - Purpose: Combines preprocessing with initial AST creation
        - Operations
            - Validates UTF-8 encoding and Unix line endings
            - Converts tabs to 4 spaces
            - Handles escape sequences
            - Creates Line AST nodes with
                - value: line text
                - indent: leading spaces count
                - position: Location with line/column/offset
                - verbatim_marker: None initially

    2.2. Pass 2: Verbatim Block Marking (verbatim_marker.py)

        - Function: mark_verbatim_blocks() at line 116
        - Input: Document[Line] nodes
        - Output: Document[Line] with verbatim markers, Dict[int, VerbatimInfo]
        - Purpose: Must run first as verbatim blocks can contain ANY text
        - Operations
            - Uses 3-state machine: NORMAL → POTENTIAL_VERBATIM → IN_VERBATIM
            - Marks verbatim lines by setting verbatim_marker = "##VERBATIM_BLOCK##"
            - Handles in-flow and stretched verbatim formats
            - Stores metadata in VerbatimInfo
                - title, label, parameters
                - start_line, end_line (1-based)
                - mode: 'in-flow' or 'stretched'
                - indent_level

    2.3. Pass 3: Block Tree Building (block_split.py)

        - Function: build_block_tree() at line 298
        - Input: Document[Line] with verbatim markers, ParserContext
        - Output: Document[GenericBlock] hierarchical tree
        - Purpose: Transform flat lines into hierarchical structure
        - Operations
            - Groups consecutive lines at same indentation
            - Creates GenericBlock nodes with
                - indent: indentation level
                - lines: text lines (with verbatim markers preserved)
                - children: nested blocks
                - position: Location info
            - Validates indentation (must be multiples of 4)
            - Handles list item boundaries

    2.4. Pass 4: Block Type Resolution (block_parse.py)

        - Function: identify_block_types() at line 693
        - Input: Document[GenericBlock], ParserContext
        - Output: Document with specific AST node types
        - Purpose: Transform GenericBlock → specific types
        - Operations
            - Post-order traversal (children before parents)
            - Disambiguation rules
                - Title: Single line + BLANK LINE + indented content
                - List: Line with list marker + siblings/children
                - Paragraph: Default when ambiguous
            - Creates AST nodes
                - Session: Contains title (as attribute) + content
                - Paragraph: Text content
                - List: Container for ListItem nodes
                - ListItem: List entry with marker
                - Verbatim: Preserved content blocks
                - Annotation: Metadata directives

    2.5. Pass 5: Inline Element Parsing (inline_parse.py)

        - Function: parse_inlines() at line 118
        - Input: Document with typed block nodes
        - Output: Document with inline content parsed
        - Purpose: Parse text formatting within blocks
        - Operations
            - Only processes text blocks (Paragraph, Heading, ListItem)
            - Skips Verbatim blocks
            - Parses inline formats (bold, italic, code, #math#, [[references]])
            - Creates inline AST nodes
                - Text: Plain text
                - Strong: Bold text with children
                - Emphasis: Italic text with children
                - InlineCode: Monospace code (value only)
                - InlineMath: Math formulas (value only)
                - Reference: Cross-references with target

    2.6. Information Flow Between Passes

        1. ParserContext (context.py) carries information
        	- source_text: Original text for reference
        	- verbatim_info: Dict[line_num, VerbatimInfo]
        	- Methods: is_verbatim_line(), get_verbatim_info()
        2. AST Node Types (ast/nodes.py)
        	- Base: Node with type, position, data
        	- Abstract: Parent (has children), Literal (has value)
        	- Document: Document (root with annotations)
        	- Blocks: Block, GenericBlock, Session, Heading, Paragraph, List, ListItem, Verbatim
        	- Inline: Text, Strong, Emphasis, InlineCode, InlineMath, Reference
        	- Metadata: Annotation, Line
        3. Position Preservation
        	- All nodes maintain Location with start/end Position
        	- Position has line (1-based), column (1-based), offset (0-based)
        	- Enables accurate error reporting and IDE features

    2.7. Key Design Principles

        1. Pure AST Pipeline: Every pass works with AST nodes, no string manipulation after Pass
        2. Position Preservation: All elements maintain original line numbers
        3. Clear Separation: Each pass has specific inputs/outputs and responsibilities
        4. Testability: Each pass can be tested independently
        5. Extensibility: New passes can be added without changing existing ones





3. The Verbatim Confusion

        In the first prototypes for the parser, we did not realize that you did not have to parse the verbatim blocks, just mark the liines to avoid. Hence it was fully parsed in pass 1.

        This caused a lot of pain, because now passes were all mixed, somestuff was in src string, others in full nodes.
        Worse it removed the verbatim block element from where it should be inserted (nesting determinse), causing more confugsion

4. The Annotation Confusion

    Annotations are attached to their following element, and this caused another confusion where annotations were 
        parsed before, than kept in a differnet area only to be reatached.

5. Problems with the current Code 

        1.  Verbatim Marking must come first

        	Even before line normalization because there we process lines, for example replacing tabs with spaces.
        	This is correct for txxt, but may not be for the verbatim block content, that's the whole point: you cannot do anythihg on the content (except extrack txxt nesting level whispace if in-flow)

        2. Verbatim Info

        	Now, verbatim lines scanning is coupled with the actual parsing, so we parse it too early, before we have an AST of elements. This forces us to, beyong the AST keep passing verbatin objects parsed info through contexts, which is not right.

        3. Pass 4: Block parsing

        	Nor verbatim elements nor annotatons should be parsed before this phase.
        	As long as you don't scan the verbatim content lines trying to parse it, they can be done just any other element, parse as you find them.

        	Anottatations can be done like other elementes. 

        	The right way to handle this is that this phase would either not nest items (but we should know their blocks/ levels)
        	or should just have a list of elements on each level (nested, atree), but it should not 

        	-  do special handling of verbatim info
        	- connect annotations to their elements
        	Bue we're not creating a document on phase 3, wrong

        4. Decoupled Document Assembly

        	You removed this step during the refactor and now are handling documents all around
        	In this step we should assemble the document. 
        	This means that we would iterate through the ast tree, and say, attach annotations to their elements (which can be the document root element ), add parsing metadata, etc

        5. Big No No

        	The biggest issue here is that information is carried : 

        	- through ast nodes (good)
        	- a side channel only for certain infos on certain nodes (verbatim annotations through context)
        	- things like actual indentation validation cannot happen in pass 1, has to be later
        	- bundle a document too early, making late stage assembly and rasoning harder

        The implementation is butchering the enitre desine. 
        Task read this and assess it's veridict (feel free to push back and propose alternative viewws)