use txxt::tokenizer::Lexer;
use txxt::ast::tokens::Token;

fn main() {
    // Focus on underscore cases which seem most problematic
    let test_cases = vec![
        "ðŸŽ‰_italic_",      // Expected: "ðŸŽ‰", "_", "italic", "_"  / Actual: "ðŸŽ‰_italic", "_"
        "cafÃ©_italic_",    // Expected: "cafÃ©", "_", "italic", "_"  / Actual: "cafÃ©_italic", "_" 
        "ðŸŽ‰@citation",     // Expected: "ðŸŽ‰@citation" / Actual: "ðŸŽ‰", ???
        "cafÃ©@citation",   // Expected: "cafÃ©@citation" / Actual: ???
    ];

    for input in test_cases {
        println!("\n=== Input: {:?} ===", input);
        
        let mut lexer = Lexer::new(input);
        let tokens = lexer.tokenize();
        
        println!("Tokens:");
        for (i, token) in tokens.iter().enumerate() {
            match token {
                Token::Text { content, span } => {
                    println!("  [{}] Text: {:?} @ col {}-{}", i, content, span.start.column, span.end.column);
                }
                Token::ItalicDelimiter { span } => {
                    println!("  [{}] ItalicDelimiter @ col {}-{}", i, span.start.column, span.end.column);
                }
                Token::AtSign { span } => {
                    println!("  [{}] AtSign @ col {}-{}", i, span.start.column, span.end.column);
                }
                Token::Eof { .. } => {},
                _ => {
                    println!("  [{}] Other token: {:?}", i, token);
                }
            }
        }
    }
    
    // Let's also trace the character-by-character logic for "ðŸŽ‰_italic_"
    println!("\n=== Character analysis for \"ðŸŽ‰_italic_\" ===");
    let input = "ðŸŽ‰_italic_";
    for (i, ch) in input.chars().enumerate() {
        println!("  [{}] '{}' U+{:04X} is_whitespace={} is_alphanumeric={}", 
                 i, ch, ch as u32, ch.is_whitespace(), ch.is_alphanumeric());
    }
}