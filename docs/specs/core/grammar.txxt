:: title :: txxt Block Grammar
:: author :: Arthur Debert
:: pub-date :: 2025-10-18

This document is part of the txxt syntax tree documentation. Together with @scanner-tokens.txxt, it defines the complete syntax and structure of the txxt format.

- Scanner Tokens [./scanner-tokens.txxt] defines the low-level scanner tokens
- Semantic Tokens: [./semantic-tokens.txxt] defines semantic node types
- Grammar [./grammar.txxt] (this document) defines how blocks are constructed from scanner tokens

This document specifies how block elements in a txxt document are constructed from scanner tokens using compositional patterns. It focuses on format-only tokenization without semantic interpretation.

The grammar is represented using compositional rules that combine scanner tokens into meaningful structures. Pattern recognition uses local token analysis rather than global document properties, ensuring deterministic and reliable parsing behavior.

1. Compositional Patterns

    Block elements are constructed from scanner tokens using compositional rules. These patterns define how tokens combine to form meaningful structures without making semantic decisions.

    1.1. Annotation Pattern

        Annotations combine txxt markers with labels and optional content:
        <Annotation> = <TxxtMarker> <Whitespace> <Text> <Whitespace> <TxxtMarker> <Text>?
        :: grammar

        Example: `:: note :: This is an annotation`

    1.2. Definition Pattern

        Definitions combine text with txxt markers, optionally with parameters:
        <SimpleDefinition> = <Text> <Whitespace> <TxxtMarker>
        <ParameterizedDefinition> = <Text> <Colon> <Text> <Whitespace> <TxxtMarker>
        :: grammar

        Examples: `Term ::` or `Term: param ::`

    1.3. VerbatimTitle Pattern

        Verbatim titles combine text with colons:
        <VerbatimTitle> = <Text> <Colon>
        :: grammar

        Example: `Python example:`

    1.4. VerbatimLabel Pattern

        Verbatim labels combine txxt markers with identifiers:
        <VerbatimLabel> = <TxxtMarker> <Whitespace> <Identifier>
        :: grammar

        Example: `:: python`

    1.5. Parameters Pattern

        Parameters combine identifiers, equals signs, and values:
        <Parameter> = <Identifier> <Equals> <Value>
        <ParameterList> = <Parameter> (<Comma> <Whitespace> <Parameter>)*
        :: grammar

        Example: `version=3.11,style=functional`

    1.6. Verbatim Wall Structure

        Verbatim blocks use wall architecture for content preservation:
        <VerbatimBlock> = <VerbatimTitle> <IndentationWall> <IgnoreTextSpan> <VerbatimLabel>
        :: grammar

        The wall structure separates formatting concerns from content preservation:
        - `IndentationWall`: Defines indentation level and type (InFlow/Stretched)
        - `IgnoreTextSpan`: Contains raw content without formatting processing

2. Token Categories

    Scanner tokens are organized into categories based on their role in composition:

    2.1. Content Tokens

        Tokens that carry textual content:
        - `Text`: Plain text content
        - `Whitespace`: Space and tab characters
        - `Identifier`: Structured identifiers

    2.2. Structural Tokens

        Tokens that define document structure:
        - `Indent`: Indentation level markers
        - `Dedent`: Indentation reduction markers
        - `BlankLine`: Empty or whitespace-only lines
        - `Newline`: Line break characters
        - `Eof`: End of file marker

    2.3. Formatting Tokens

        Tokens that apply text formatting:
        - `BoldDelimiter`: Bold text markers (*)
        - `ItalicDelimiter`: Italic text markers (_)
        - `CodeDelimiter`: Code text markers (`)
        - `MathDelimiter`: Math text markers (#)

    2.4. Punctuation Tokens

        Tokens that provide structural punctuation:
        - `Colon`: Single colon (:)
        - `Equals`: Equals sign (=)
        - `Comma`: Comma separator (,)
        - `Period`: Period (.)
        - `Dash`: Dash (-)

    2.5. Marker Tokens

        Tokens that identify special structures:
        - `TxxtMarker`: Double colon (::)
        - `SequenceMarker`: List and session markers
        - `RefMarker`: Reference markers ([, ])
        - `AtSign`: Citation marker (@)
        - `Hash`: Session reference marker (#)

    2.6. Reference Tokens

        Tokens for links and citations:
        - `CitationRef`: Citation references
        - `PageRef`: Page references
        - `SessionRef`: Session references
        - `FootnoteRef`: Footnote references

    2.7. Ignore Tokens

        Tokens for verbatim content preservation:
        - `IndentationWall`: Wall position and type information
        - `IgnoreTextSpan`: Raw content without processing

3. Composition Rules

    Rules for combining tokens into meaningful structures:

    3.1. Line Composition

        Lines are composed from span elements:
        <Line> = <SpanElement> (<Whitespace> <SpanElement>)* <Newline>
        :: grammar

    3.2. Block Composition

        Blocks are composed from lines with proper indentation:
        <Block> = <Indent> <Line>+ <Dedent>
        :: grammar

    3.3. Container Composition

        Containers group related blocks:
        <Container> = <Indent> <Block>+ <Dedent>
        :: grammar

4. Disambiguation Rules

    Rules for resolving conflicts when multiple interpretations are possible:

    4.1. Token Precedence

        Order of token recognition (first match wins):
        1. Escaped characters (highest precedence)
        2. Verbatim block boundaries
        3. Annotation markers
        4. Sequence markers
        5. Reference spans
        6. Formatting spans
        7. Text spans (lowest precedence)

    4.2. Context Rules

        Context-dependent interpretation:
        - Verbatim content: All tokens treated as `IgnoreTextSpan`
        - Annotation content: Text tokens only
        - List items: Sequence markers required
        - Definitions: Must end with `TxxtMarker`

5. Error Handling

    How the parser handles malformed or ambiguous input:

    5.1. Graceful Degradation

        When syntax is malformed, fall back to simpler interpretation:
        - Invalid annotation → Text line
        - Incomplete formatting → Literal text
        - Malformed list → Text line
        - Unclosed verbatim → Text line
        - Misplaced syntactic markers → Preserved as semantic tokens for error reporting

    5.2. Recovery Strategies

        Methods for continuing parsing after errors:
        - Skip malformed tokens and continue
        - Close incomplete structures at block boundaries
        - Preserve all content as text when structure unclear
        - Never fail completely - always produce output

:: note :: This grammar specification defines compositional patterns for scanner tokens. For complete token definitions, see @scanner-tokens.txxt.
