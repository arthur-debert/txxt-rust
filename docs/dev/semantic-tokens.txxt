:: title :: Semantic Token Architecture
:: author :: Arthur Debert
:: pub-date :: 2025-10-18

This document describes the semantic token architecture in the txxt parsing pipeline, which has been implemented as part of the Token Refactor.

1. Current Architecture

    The txxt parsing pipeline uses a three-phase approach with clear separation of concerns:

    Phase 1: Lexer (txxt str -> ScannerTokenList)
        a. Verbatim Scanner: marks verbatim lines that are off-limits for processing as txxt
        b. Token List: creates the token stream at low level tokens -> scanner token list

    Phase 2: Parser (ScannerTokenList -> AST tree node)
        a. Semantic Analysis (ScannerTokenList → SemanticTokenList)
            Elevates the low-level scanner token stream into a higher-level stream of semantic nodes.
            Structural tokens like `Indent`, `Dedent`, and `BlankLine` are passed through unchanged.
        b. AST Construction (SemanticTokenList -> AST Tree Node)
            Consumes the rich, flat stream and applies the grammar to construct the final AST.
            This is the only phase that builds a tree structure.
        c. Inline Parsing: Handle inlines within blocks (ScannerToken -> AST node)

    Phase 3: Assembly (AST tree node -> AST document node)
        a. Document Wrapping: wraps the parsed AST in a Document node
        b. Annotations Attachments: from the content tree to node's annotation's field

2. Token Architecture

    The token architecture follows a clear hierarchy:

    Scanner Tokens → Semantic Tokens → Block Elements → Document

    2.1. Scanner Tokens

        Low-level format-only tokens produced by the lexer:
        - Content tokens: `Text`, `Whitespace`, `Identifier`
        - Structural tokens: `Indent`, `Dedent`, `BlankLine`, `Newline`, `Eof`
        - Formatting tokens: `BoldDelimiter`, `ItalicDelimiter`, `CodeDelimiter`, `MathDelimiter`
        - Punctuation tokens: `Colon`, `Equals`, `Comma`, `Period`, `Dash`
        - Marker tokens: `TxxtMarker`, `SequenceMarker`, `AtSign`, `Hash`, `Caret`
        - Reference tokens: `CitationRef`, `PageRef`, `SessionRef`, `FootnoteRef`
        - Ignore tokens: `IndentationWall`, `IgnoreTextSpan`
        - Verbatim tokens: `VerbatimTitle`, `VerbatimLabel`

    2.2. Semantic Tokens

        Higher-level constructs that bridge scanner tokens and block elements:
        - `TxxtMarker`: Fundamental :: marker
        - `Label`: Structured identifiers
        - `Parameters`: Key-value metadata
        - `Sequence Marker`: List and session numbering
        - `Text Span`: Basic text content
        - `Sequence Text Line`: Line with sequence marker
        - `Plain Text Line`: Simple text content
        - `Ignore Line`: Preserved verbatim content
        - `Blank Line`: Whitespace-only lines

3. Wall Architecture for Verbatim Content

    Verbatim blocks use a wall architecture to separate formatting concerns from content preservation:

    3.1. IndentationWall Token

        Defines the indentation structure for verbatim content:
        - `level`: Indentation level in spaces
        - `wall_type`: Type of wall (InFlow or Stretched)
        - `span`: Source position information

    3.2. IgnoreTextSpan Token

        Contains raw content without formatting processing:
        - `content`: Raw text content
        - `span`: Source position information

    3.3. Verbatim Block Structure

        Complete verbatim block token sequence:
        1. `VerbatimTitle`: Title line ending with colon
        2. `IndentationWall`: Wall position and type
        3. `IgnoreTextSpan`: Raw content lines
        4. `VerbatimLabel`: Label line with txxt marker

4. Benefits of Current Architecture

    4.1. Clear Separation of Concerns

        - Format recognition (scanner tokens)
        - Syntactic structure (semantic tokens)
        - Semantic meaning (block elements)

    4.2. Improved Maintainability

        - Cleaner parsing logic
        - Better error handling
        - Easier testing and debugging
        - More maintainable code

    4.3. Compositional Design

        - Tokens combine using well-defined patterns
        - Reusable components across different elements
        - Clear token precedence and disambiguation rules

5. Implementation Status

    The semantic token architecture has been fully implemented as part of the Token Refactor:

    ✅ Scanner token definitions updated
    ✅ Semantic token definitions implemented
    ✅ Wall architecture for verbatim content
    ✅ Compositional patterns documented
    ✅ Grammar specification updated
    ✅ All tests passing

:: note :: This document describes the implemented semantic token architecture. For detailed specifications, see the core specification documents.