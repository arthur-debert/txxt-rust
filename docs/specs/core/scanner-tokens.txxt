:: title :: txxt Scanner Tokens Reference
:: author :: Arthur Debert
:: pub-date :: 2025-10-18

This document defines the low-level scanner tokens used in the txxt format. These are the atomic tokens that form the foundation of the txxt parsing pipeline, produced by the lexer and consumed by the parser.

- Scanner Tokens [./scanner-tokens.txxt] defines the low-level scanner tokens (this document)
- Semantic Tokens: [./semantic-tokens.txxt] defines semantic node types
- Grammar [./grammar.txxt] defines how blocks are constructed from scanner tokens

This document defines the low-level scanner tokens used in the txxt format. These tokens focus on format-only recognition without semantic interpretation, providing the building blocks for compositional parsing.

1. Token Categories

    Scanner tokens are organized into categories based on their role in format recognition and composition:

    1.1. Content Tokens

        Tokens that carry textual content without special formatting:
        - `Text`: Plain text content
        - `Whitespace`: Space and tab characters
        - `Identifier`: Structured identifiers (letters, numbers, dots, underscores, hyphens)

    1.2. Structural Tokens

        Tokens that define document structure and indentation:
        - `Indent`: Indentation level markers (4-space increments)
        - `Dedent`: Indentation reduction markers
        - `BlankLine`: Empty or whitespace-only lines
        - `Newline`: Line break characters
        - `Eof`: End of file marker

    1.3. Formatting Tokens

        Tokens that apply text formatting:
        - `BoldDelimiter`: Bold text markers (*)
        - `ItalicDelimiter`: Italic text markers (_)
        - `CodeDelimiter`: Code text markers (`)
        - `MathDelimiter`: Math text markers (#)

    1.4. Punctuation Tokens

        Tokens that provide structural punctuation:
        - `Colon`: Single colon (:)
        - `Equals`: Equals sign (=)
        - `Comma`: Comma separator (,)
        - `Period`: Period (.)
        - `Dash`: Dash (-)
        - `LeftBracket`: Left bracket ([)
        - `RightBracket`: Right bracket (])
        - `LeftParen`: Left parenthesis (()
        - `RightParen`: Right parenthesis ())

    1.5. Marker Tokens

        Tokens that identify special structures:
        - `TxxtMarker`: Double colon (::)
        - `SequenceMarker`: List and session markers
        - `AtSign`: Citation marker (@)
        - `Hash`: Session reference marker (#)
        - `Caret`: Footnote marker (^)

    1.6. Reference Tokens

        Tokens for links and citations:
        - `CitationRef`: Citation references [@key]
        - `PageRef`: Page references [p. 123]
        - `SessionRef`: Session references [#1.2]
        - `FootnoteRef`: Footnote references [^label]

    1.7. Ignore Tokens

        Tokens for verbatim content preservation:
        - `IndentationWall`: Wall position and type information
        - `IgnoreTextSpan`: Raw content without processing

    1.8. Verbatim Tokens

        Tokens specific to verbatim blocks:
        - `VerbatimTitle`: Title line ending with colon
        - `VerbatimLabel`: Label line with txxt marker

2. Token Recognition Rules

    Rules for recognizing tokens from character sequences:

    2.1. Character Classes

        Basic character classes used in token recognition:
        - `whitespace`: Space and tab characters
        - `letter`: ASCII letters (a-z, A-Z)
        - `digit`: ASCII digits (0-9)
        - `alphanumeric`: Letters and digits
        - `line-break`: Newline character (\n)
        - `any-char`: Any character except newline

    2.2. Escaping Rules

        Backslash removes special meaning from following character:
        - `escaped-char`: Backslash followed by any character
        - `literal-char`: Any character except special markers

    2.3. Token Precedence

        Order of token recognition (first match wins):
        1. Escaped characters (highest precedence)
        2. Verbatim block boundaries
        3. Annotation markers
        4. Sequence markers
        5. Reference spans
        6. Formatting spans
        7. Text spans (lowest precedence)

3. Wall Architecture for Verbatim Content

    Verbatim blocks use a wall architecture to separate formatting concerns from content preservation:

    3.1. IndentationWall Token

        Defines the indentation structure for verbatim content:
        - `level`: Indentation level in spaces
        - `wall_type`: Type of wall (InFlow or Stretched)
        - `span`: Source position information

        Wall Types:
        - `InFlow(base_indent)`: Content indented relative to title
        - `Stretched`: Content starts at absolute column 1

    3.2. IgnoreTextSpan Token

        Contains raw content without formatting processing:
        - `content`: Raw text content
        - `span`: Source position information

    3.3. Verbatim Block Structure

        Complete verbatim block token sequence:
        1. `VerbatimTitle`: Title line ending with colon
        2. `IndentationWall`: Wall position and type
        3. `IgnoreTextSpan`: Raw content lines
        4. `VerbatimLabel`: Label line with txxt marker

4. File Organization Structure

    Tokens are organized in the codebase following a clear structure:

    4.1. Core Token Definitions

        - `src/ast/elements/scanner_tokens.rs`: Main token enum and types
        - `src/ast/tokens/`: Individual token type definitions
        - `src/lexer/elements/`: Token-specific lexer implementations

    4.2. Token Processing

        - `src/lexer/core/`: Core lexer infrastructure
        - `src/lexer/pipeline/`: Token processing pipeline
        - `src/tools/detokenizer/`: Token-to-text reconstruction

5. Examples

    Examples demonstrating token recognition:

    5.1. Annotation Tokens

        Input: `:: note :: This is an annotation`
        Tokens: `TxxtMarker` `Whitespace` `Text` `Whitespace` `TxxtMarker` `Whitespace` `Text`

    5.2. Verbatim Block Tokens

        Input:
        ```
        Python example:
            def hello():
                print("Hello!")
        :: python
        ```
        Tokens: `VerbatimTitle` `IndentationWall` `IgnoreTextSpan` `VerbatimLabel`

    5.3. Reference Tokens

        Input: `See [@smith2023] for details`
        Tokens: `Text` `Whitespace` `LeftBracket` `AtSign` `Text` `RightBracket` `Whitespace` `Text`

6. Error Handling

    How the scanner handles malformed input:

    6.1. Graceful Degradation

        When syntax is malformed, fall back to simpler interpretation:
        - Invalid annotation → Text tokens
        - Incomplete formatting → Literal text tokens
        - Malformed list → Text tokens
        - Unclosed verbatim → Text tokens

    6.2. Recovery Strategies

        Methods for continuing tokenization after errors:
        - Skip malformed characters and continue
        - Close incomplete structures at line boundaries
        - Preserve all content as text when structure unclear
        - Never fail completely - always produce tokens

:: note :: This scanner tokens reference defines format-only tokens for txxt. For compositional patterns and block grammar, see @grammar.txxt.
