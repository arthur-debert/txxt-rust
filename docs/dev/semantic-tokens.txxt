Proposal: Semantic Token Stage

1. Context

	Currently txxt parsing happens as follows: 

	Phase 1: Lexer (txxt str -> TokenTree)
		a. Verbatim Scanner: marks verbatim lines that are off-limits for processing as txxt
		b. Token List: creates the token stream at low level tokens -> token list
		c. Token Tree: converts the token list to a tree, using indent/dedent tokens -> TokenTree
	Phase 2: Parser (TokenTree -> AST tree node)
		a. Block Parsing: Convert TokenTrees into typed AST nodes -> AST node (no inlines)
		b. Inline Parsing: Handle inlines within blocks -> AST node
	Phase 3: Assembly (AST tree node -> AST document node)
		a. Document Wrapping: wraps the parsed AST in a Document node.
		b. Annotations Attachments: from the content tree to node's annotation's field.

	While Phase 2, the block parsing is underway. The parser operates on low level tokens (as in <PERIOD>, <WHITESPACE>), which makes the mental mapping from low level tokens to full AST elements challenging and indirect.

2. New Stage: Semantic Token Parsing

	In order to make the hardest parsing stage 2.a easier, we will introduce a new stage before 2.a, Semantic Token Parsing. 


	2.1 Semantic Token Parsing (TokenTree -> SemanticTokenTree)
		- This new stage consumes the TokenTree.
		- It iterates through the tokens field of each TokenTree node.
		- It parses the flat list of tokens at that level into a structured list of Semantic Token objects.
		- It recursively does this for all children.
		- The output is a new tree structure, called a SemanticTokenTree, which has the same hierarchical structure as TokenTree but with higher-level semantic tokens.

	2.2 The new Pipeline including 2.1
		
		Therefore, the new parsing pipeline will look like

		Phase 1: Lexer (txxt str -> TokenTree)
			a. Verbatim Scanner: marks verbatim lines that are off-limits for processing as txxt
			b. Token List: creates the token stream at low level tokens -> token list
			c. Token Tree: converts the token list to a tree, using indent/dedent tokens -> TokenTree
		Phase 2: Parser (TokenTree -> AST tree node)
			a. Semantic Token Parsing: Convert TokenTrees into SemanticTokenTrees
			b. Block Parsing: Convert SemanticTokenTrees into typed AST nodes -> AST node (no inlines)
			c. Inline Parsing: Handle inlines within blocks -> AST node
		Phase 3: Assembly (AST tree node -> AST document node)
			a. Document Wrapping: wraps the parsed AST in a Document node.
			b. Annotations Attachments: from the content tree to node's annotation's field.

3. Semantic Tokens: 

	The conversion between scanner and Semantic Tokens is based on the syntax [./docs/specs/core/syntax.txxt] and aims to output a higher level representation that is much closer to the parser level. 

	Verbatim: 

		<text span> <colon>
			<ignore line>
		<label> <parameters>?
    :: syntax

	And for annotations: 
		<txxt marker> <label> <txxt-marker> <text-line> 
	:: syntax

 .  Note that semantic tokes are not element bound, as in annotation token of any sorts. We won't know about elements until parsing has taken place, which will come later. Semenatic tokes group lower level character tokens into higher level langauge concepts as parameters, label, sequence text line.

4. Semantic Token Types and Definitions

	4.1 Proposed SemanticToken AST Node Types

		SemanticToken::
			Component-level semantic tokens that bridge scanner tokens and AST elements.
			Provides structured, reusable components rather than line-based tokens.
			Emphasizes composability and eliminates duplication across elements.

		SemanticTokenTree::
			Tree structure containing SemanticTokens with hierarchical children.
			Mirrors TokenTree structure but with higher-level semantic meaning.

	4.2 Semantic Tokens Definitions

		These are describe in the semantic nodes [docs/specs/core/semantic-nodes.txxt]

5. Implementation: 
 
	5.1 Renaming Tokens

		Now that we have two token types, having tokens vs Semantic Tokens is bound to create confusion. We will rename, in the AST, the current Tokens to ScannerTokens, as opposed to SemanticTokens.

		While these do share considerably in traits/types, they have specialization and being able to work with scanner or semantic trees with type safety will be worth it. 

		These should reflect code, be it modules or packages, as in ast/tokens.rs -> ast/scanner_tokens.rs


	5.2 Validate Semantic Token Definition List

		This should be validated, then formalized in the docs/specs/core/syntax.txxt document.

	5.3 Implement Infrastructure for Semantic Tokens

		The AST nodes, etc.

	5.4 Add SemanticTokenTree txxt-binary support

		Add the support for txxt binary to output these, as it's greatly useful for debugging.

	5.5 Add Semantic Token support for Corpora

		Our txxt source tool, corpora can generate the txxt data in all phases of the pipeline, which are useful for testing.

	5.6 Implement the Semantic Token parsing phase

	5.7 Write Unit Tests

		These should have a few tests per token. We can use the txxt binary or corpora to generate this correctly from actual parsing stages, but then we copy and use them manually in the tests, to make it more visual what the transformation of input/output should look like

	5.8 Don't break parsing as it is

		This branch will not adapt the block parser to receive Semantic Tokens. Hence we cannot just plug in the phase, else all will break. We will implement the phase, but not include it in the pipeline.